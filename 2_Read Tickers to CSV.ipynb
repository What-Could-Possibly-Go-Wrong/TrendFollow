{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:24:50.697496Z",
     "iopub.status.busy": "2023-04-08T20:24:50.697496Z",
     "iopub.status.idle": "2023-04-08T20:24:52.537597Z",
     "shell.execute_reply": "2023-04-08T20:24:52.537597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ticker\n",
      "0       A2M\n",
      "1       ABC\n",
      "2       ABP\n",
      "3       AGL\n",
      "4       AIA\n",
      "...     ...\n",
      "1172      X\n",
      "1173    XPO\n",
      "1174    XRX\n",
      "1175   YETI\n",
      "1176     ZD\n",
      "\n",
      "[1177 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def read_tickers_from_folder(folder_path):\n",
    "    # Liste der Dateinamen im Ordner\n",
    "    file_names = os.listdir(folder_path)\n",
    "\n",
    "    # Filtere nur CSV-Dateien\n",
    "    csv_files = [file for file in file_names if file.endswith('.csv')]\n",
    "\n",
    "    # Liste, um die eingelesenen DataFrames zu speichern\n",
    "    dataframes = []\n",
    "\n",
    "    # Lese jede CSV-Datei und f√ºge sie zur Liste der DataFrames hinzu\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(folder_path, csv_file)\n",
    "        df = pd.read_csv(file_path, header=None, names=['Ticker'])\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Kombiniere alle DataFrames in einem einzigen DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Lese alle CSV-Dateien im Ordner 'Tickers' und erstelle ein DataFrame\n",
    "folder_path = 'Tickers'\n",
    "all_tickers_df = read_tickers_from_folder(folder_path)\n",
    "\n",
    "# Zeige das kombinierte DataFrame\n",
    "\n",
    "print(all_tickers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:24:52.557703Z",
     "iopub.status.busy": "2023-04-08T20:24:52.553695Z",
     "iopub.status.idle": "2023-04-08T20:33:46.737882Z",
     "shell.execute_reply": "2023-04-08T20:33:46.736881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- A2M: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- ABP: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- AKE: No timezone found, symbol may be delisted\n",
      "10\n",
      "\n",
      "1 Failed download:\n",
      "- ANN: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- SQ2: No timezone found, symbol may be delisted\n",
      "20\n",
      "\n",
      "1 Failed download:\n",
      "- BKL: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "30\n",
      "\n",
      "1 Failed download:\n",
      "- BKW: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- BRG: No timezone found, symbol may be delisted\n",
      "40\n",
      "\n",
      "1 Failed download:\n",
      "- CCP: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- CCX: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- CHC: No data found for this date range, symbol may be delisted\n",
      "50\n",
      "\n",
      "1 Failed download:\n",
      "- COH: No data found for this date range, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- CRN: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "60\n",
      "\n",
      "1 Failed download:\n",
      "- CXO: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- DEG: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "70\n",
      "80\n",
      "\n",
      "1 Failed download:\n",
      "- GNC: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- HDN: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- HLS: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "90\n",
      "100\n",
      "\n",
      "1 Failed download:\n",
      "- IRE: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- IVC: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- JBH: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "110\n",
      "\n",
      "1 Failed download:\n",
      "- MP1: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- MPL: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- MTS: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "120\n",
      "\n",
      "1 Failed download:\n",
      "- NHF: No timezone found, symbol may be delisted\n",
      "130\n",
      "140\n",
      "150\n",
      "\n",
      "1 Failed download:\n",
      "- RWC: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- S32: No timezone found, symbol may be delisted\n",
      "160\n",
      "\n",
      "1 Failed download:\n",
      "- SGM: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "170\n",
      "\n",
      "1 Failed download:\n",
      "- STO: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- TCL: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- TLC: No timezone found, symbol may be delisted\n",
      "180\n",
      "\n",
      "1 Failed download:\n",
      "- TNE: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- UWL: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- VUK: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "\n",
      "1 Failed download:\n",
      "- WBC: No timezone found, symbol may be delisted\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "\n",
      "1 Failed download:\n",
      "- AENA: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- MTS: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "250\n",
      "260\n",
      "\n",
      "1 Failed download:\n",
      "- NTGY: No timezone found, symbol may be delisted\n",
      "\n",
      "1 Failed download:\n",
      "- ROVI: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "270\n",
      "\n",
      "1 Failed download:\n",
      "- SGRE: No timezone found, symbol may be delisted\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No timezone found, symbol may be delisted\n",
      "340\n",
      "350\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: 1d data not available for startTime=-2208971040 and endTime=1680753600. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "                 Open       High        Low      Close  Adj Close      Volume  \\\n",
      "Date                                                                            \n",
      "1995-04-04   2.937500   2.968750   2.812500   2.953125   2.268681  40387200.0   \n",
      "1995-04-05   2.906250   2.968750   2.843750   2.843750   2.184655  12236800.0   \n",
      "1995-04-06   2.843750   2.937500   2.843750   2.890625   2.220667   3776000.0   \n",
      "1995-04-07   2.906250   2.906250   2.843750   2.843750   2.184655   1920800.0   \n",
      "1995-04-10   2.843750   2.906250   2.843750   2.875000   2.208663   2047200.0   \n",
      "...               ...        ...        ...        ...        ...         ...   \n",
      "2023-03-30  76.160004  76.360001  74.790001  75.830002  75.830002    191800.0   \n",
      "2023-03-31  76.500000  78.349998  76.190002  78.050003  78.050003    293900.0   \n",
      "2023-04-03  77.720001  78.239998  76.889999  77.800003  77.800003    283300.0   \n",
      "2023-04-04  77.760002  78.419998  75.779999  76.510002  76.510002    188100.0   \n",
      "2023-04-05  76.050003  76.519997  75.309998  75.809998  75.809998    274800.0   \n",
      "\n",
      "           ticker  \n",
      "Date               \n",
      "1995-04-04    ABC  \n",
      "1995-04-05    ABC  \n",
      "1995-04-06    ABC  \n",
      "1995-04-07    ABC  \n",
      "1995-04-10    ABC  \n",
      "...           ...  \n",
      "2023-03-30     ZD  \n",
      "2023-03-31     ZD  \n",
      "2023-04-03     ZD  \n",
      "2023-04-04     ZD  \n",
      "2023-04-05     ZD  \n",
      "\n",
      "[7714952 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def download_data(ticker):\n",
    "    data = yf.download(ticker, start=\"1900-01-01\", end=\"2023-04-06\", progress=False)\n",
    "    return data\n",
    "\n",
    "def SaveStockData2CSV(df, folder='Data', filename='AllStockDataDownload.csv'):\n",
    "    # √úberpr√ºfe, ob der Ordner existiert. Wenn nicht, erstelle den Ordner.\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Speichere das DataFrame als CSV-Datei im Ordner \"Data\"\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    df.to_csv(file_path, index=True)\n",
    "\n",
    "all = pd.DataFrame()\n",
    "data = pd.DataFrame()\n",
    "\n",
    "all_tickers = all_tickers_df['Ticker'].tolist()\n",
    "i = 0\n",
    "for ticker in all_tickers:\n",
    "    data = download_data(ticker)\n",
    "    data['ticker'] = ticker\n",
    "    all = pd.concat([all,data])\n",
    "    i=i+1\n",
    "    if (i%10 == 0):\n",
    "        print(i)\n",
    "print(all)\n",
    "\n",
    "SaveStockData2CSV(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:33:46.741317Z",
     "iopub.status.busy": "2023-04-08T20:33:46.741317Z",
     "iopub.status.idle": "2023-04-08T20:33:46.770090Z",
     "shell.execute_reply": "2023-04-08T20:33:46.769090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-04-04</th>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.953125</td>\n",
       "      <td>2.268681</td>\n",
       "      <td>40387200.0</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-05</th>\n",
       "      <td>2.906250</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.184655</td>\n",
       "      <td>12236800.0</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-06</th>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.890625</td>\n",
       "      <td>2.220667</td>\n",
       "      <td>3776000.0</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-07</th>\n",
       "      <td>2.906250</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.184655</td>\n",
       "      <td>1920800.0</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-10</th>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>2.843750</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>2.208663</td>\n",
       "      <td>2047200.0</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>76.160004</td>\n",
       "      <td>76.360001</td>\n",
       "      <td>74.790001</td>\n",
       "      <td>75.830002</td>\n",
       "      <td>75.830002</td>\n",
       "      <td>191800.0</td>\n",
       "      <td>ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>76.500000</td>\n",
       "      <td>78.349998</td>\n",
       "      <td>76.190002</td>\n",
       "      <td>78.050003</td>\n",
       "      <td>78.050003</td>\n",
       "      <td>293900.0</td>\n",
       "      <td>ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>77.720001</td>\n",
       "      <td>78.239998</td>\n",
       "      <td>76.889999</td>\n",
       "      <td>77.800003</td>\n",
       "      <td>77.800003</td>\n",
       "      <td>283300.0</td>\n",
       "      <td>ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>77.760002</td>\n",
       "      <td>78.419998</td>\n",
       "      <td>75.779999</td>\n",
       "      <td>76.510002</td>\n",
       "      <td>76.510002</td>\n",
       "      <td>188100.0</td>\n",
       "      <td>ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.519997</td>\n",
       "      <td>75.309998</td>\n",
       "      <td>75.809998</td>\n",
       "      <td>75.809998</td>\n",
       "      <td>274800.0</td>\n",
       "      <td>ZD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7714952 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close      Volume  \\\n",
       "Date                                                                            \n",
       "1995-04-04   2.937500   2.968750   2.812500   2.953125   2.268681  40387200.0   \n",
       "1995-04-05   2.906250   2.968750   2.843750   2.843750   2.184655  12236800.0   \n",
       "1995-04-06   2.843750   2.937500   2.843750   2.890625   2.220667   3776000.0   \n",
       "1995-04-07   2.906250   2.906250   2.843750   2.843750   2.184655   1920800.0   \n",
       "1995-04-10   2.843750   2.906250   2.843750   2.875000   2.208663   2047200.0   \n",
       "...               ...        ...        ...        ...        ...         ...   \n",
       "2023-03-30  76.160004  76.360001  74.790001  75.830002  75.830002    191800.0   \n",
       "2023-03-31  76.500000  78.349998  76.190002  78.050003  78.050003    293900.0   \n",
       "2023-04-03  77.720001  78.239998  76.889999  77.800003  77.800003    283300.0   \n",
       "2023-04-04  77.760002  78.419998  75.779999  76.510002  76.510002    188100.0   \n",
       "2023-04-05  76.050003  76.519997  75.309998  75.809998  75.809998    274800.0   \n",
       "\n",
       "           ticker  \n",
       "Date               \n",
       "1995-04-04    ABC  \n",
       "1995-04-05    ABC  \n",
       "1995-04-06    ABC  \n",
       "1995-04-07    ABC  \n",
       "1995-04-10    ABC  \n",
       "...           ...  \n",
       "2023-03-30     ZD  \n",
       "2023-03-31     ZD  \n",
       "2023-04-03     ZD  \n",
       "2023-04-04     ZD  \n",
       "2023-04-05     ZD  \n",
       "\n",
       "[7714952 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:33:46.773090Z",
     "iopub.status.busy": "2023-04-08T20:33:46.773090Z",
     "iopub.status.idle": "2023-04-08T20:33:46.848901Z",
     "shell.execute_reply": "2023-04-08T20:33:46.847811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7714952 entries, 1995-04-04 to 2023-04-05\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Open       float64\n",
      " 1   High       float64\n",
      " 2   Low        float64\n",
      " 3   Close      float64\n",
      " 4   Adj Close  float64\n",
      " 5   Volume     float64\n",
      " 6   ticker     object \n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 470.9+ MB\n"
     ]
    }
   ],
   "source": [
    "all.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
